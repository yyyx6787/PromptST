[data]
num_nodes = 170
lag = 12
horizon = 12
val_ratio = 0.2
test_ratio = 0.2
tod = False
normalizer = std
column_wise = False
default_graph = True

[model]
input_dim = 1
output_dim = 1
input_window = 12
output_window = 12

gcn_true = True
buildA_true = True
gcn_depth = 2
dropout = 0.3
subgraph_size = 20
node_dim = 40
dilation_exponential = 1
conv_channels = 32
residual_channels = 32
skip_channels = 64
end_channels = 128
layers = 3
propalpha = 0.05
tanhalpha = 3
layer_norm_affline = True
use_curriculum_learning = True
step_size1 = 2500
task_level = 0
num_split = 1
step_size2 = 100

[train]
loss_func = mask_mae
# loss_func = mae
seed = 52
batch_size = 64
epochs = 100
lr_init = 0.003
lr_decay = True
lr_decay_rate = 0.3
lr_decay_step = 20,40,55,70
early_stop = True
early_stop_patience = 20
grad_norm = True
max_grad_norm = 5
real_value = False

[test]
mae_thresh = None
mape_thresh = 0.

[log]
log_step = 20
plot = False